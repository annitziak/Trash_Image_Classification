{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augemntation - Difussion Model\n",
    "A diffusion model gradually adds noise to an image and then learns to reverse this process to generate new, realistic images from pure noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionImg2ImgPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the prompts to be used for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define category-specific configurations\n",
    "category_settings = {\n",
    "  \"cardboard\": {\n",
    "    \"prompt\": \"A perfectly clean, brand-new cardboard box, neatly presented in {items}. It has sharp edges with no creases, dirt, or damage. The object is isolated on a seamless, bright white studio backdrop with soft, even lighting.\",\n",
    "    \"items\": [\"rectangular box\", \"square box\", \"flat folded box\", \"open-top box\", \"closed shipping box\", \"tall vertical box\"],\n",
    "    \"strength\": 0.8,\n",
    "    \"guidance_scale\": 9,\n",
    "    \"image_size\": [512, 512],\n",
    "    \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "  },\n",
    "  \"glass\": {\n",
    "    \"prompt\": \"A perfectly clean, brand-new {items} with crisp reflections and pristine glass. The object is isolated on a seamless, bright white studio backdrop with soft, even lighting.\",\n",
    "    \"items\": [\"glass bottle\", \"glass jar\", \"drinking glass\", \"wine glass\", \"glass vase\"],\n",
    "    \"strength\": 0.6,\n",
    "    \"guidance_scale\": 12,\n",
    "    \"image_size\": [512, 512],\n",
    "    \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "  },\n",
    "  \"metal\": {\n",
    "    \"prompt\": \"A detailed close-up shot of a {items}, without any dents, rust, or damage. The object showcases sharp details, isolated against a seamless, bright white studio backdrop with soft, even lighting.\",\n",
    "    \"items\": [\"aluminum can\", \"tin can\", \"food can\", \"soda can\", \"drink can\", \"beverage can\"],\n",
    "    \"strength\": 0.8,\n",
    "    \"guidance_scale\": 14,\n",
    "    \"image_size\": [512, 512],\n",
    "    \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "  },\n",
    "  \"paper\": {\n",
    "    \"prompt\": \"A single, clean printer {items} lying flat on a seamless, bright white studio backdrop. The edges are perfectly straight, and the surface is pristine, free of any folds, dirt, or creases.\",\n",
    "    \"items\": [\"newspaper\", \"magazine\", \"printed document\", \"written paper sheet\", \"folded paper\", \"crumpled paper\", \"envelope\"],\n",
    "    \"strength\": 0.75,\n",
    "    \"guidance_scale\": 14,\n",
    "    \"image_size\": [512, 512],\n",
    "    \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "  },\n",
    "  \"plastic\": {\n",
    "    \"prompt\": \"A single plastic {items}, perfectly shaped with a smooth, glossy surface, free of any scratches or dents. The object is placed on an isolated, seamless, bright white studio backdrop with soft, even lighting.\",\n",
    "    \"items\": [\"water bottle\", \"beverage bottle\", \"soda bottle\", \"juice bottle\", \"milk bottle\"],\n",
    "    \"strength\": 0.75,\n",
    "    \"guidance_scale\": 14,\n",
    "    \"image_size\": [512, 512],\n",
    "    \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "  },\n",
    "  \"trash\": {\n",
    "    \"prompt\": \"A single, dirty {items} on a plain surface. The object has stains, or slight tears. The objects are casually scattered, resembling everyday trash left behind after a meal or snack. The lighting is even, highlighting textures and reflections on the different materials.\",\n",
    "    \"items\": [\"crumpled paper\", \"torn plastic wrappers\", \"empty snack pouches\", \"used napkins\"],\n",
    "    \"strength\": 0.8,\n",
    "    \"guidance_scale\": 14,\n",
    "    \"image_size\": [512, 512],\n",
    "    \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the dataset and start the image generation process using diffusion models\n",
    "### Idea : The augmented images at each catergory must all be equal to majority_class*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "input_dir = \"../data/dataset_split/train\"\n",
    "output_dir = \"../data/dataset_diffusion_balanced/train\"\n",
    "\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Count images per category\n",
    "class_counts = {cat: len(os.listdir(os.path.join(input_dir, cat))) for cat in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, cat))}\n",
    "\n",
    "majority_class = max(class_counts, key=class_counts.get)\n",
    "majority_size = class_counts[majority_class]\n",
    "target_size = majority_size * 2  # Double the majority class\n",
    "\n",
    "def preprocess_image(image_path, size):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.resize(size)\n",
    "    return image\n",
    "\n",
    "def is_black_image(image, mean_threshold=10):\n",
    "    gray = image.convert(\"L\")\n",
    "    return np.array(gray).mean() < mean_threshold\n",
    "\n",
    "for category, count in tqdm(class_counts.items(), desc=\"Balancing dataset\"):\n",
    "    settings = category_settings.get(category, category_settings[\"trash\"])\n",
    "    \n",
    "    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "        settings[\"model\"],\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "    ).to(device)\n",
    "    \n",
    "    class_path = os.path.join(input_dir, category)\n",
    "    augmented_class_path = os.path.join(output_dir, category)\n",
    "    os.makedirs(augmented_class_path, exist_ok=True)\n",
    "    \n",
    "    images = os.listdir(class_path)\n",
    "    for img_name in images:\n",
    "        shutil.copy(os.path.join(class_path, img_name), os.path.join(augmented_class_path, img_name))\n",
    "    \n",
    "    num_needed = target_size - count\n",
    "    print(num_needed)\n",
    "    max_attempts = num_needed * 4\n",
    "    attempts = 0\n",
    "    \n",
    "    while num_needed > 0 and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        img_name = random.choice(images)\n",
    "        input_image = preprocess_image(os.path.join(class_path, img_name), settings[\"image_size\"])\n",
    "\n",
    "        prompt_item = random.choice(settings.get(\"items\", [\"object\"]))\n",
    "        prompt = settings[\"prompt\"].format(items=prompt_item)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            result = pipe(\n",
    "                prompt=prompt,\n",
    "                image=input_image,\n",
    "                strength=settings[\"strength\"],\n",
    "                guidance_scale=settings[\"guidance_scale\"],\n",
    "                num_images_per_prompt=1,\n",
    "            )\n",
    "        \n",
    "        synthetic_image = result.images[0]\n",
    "        if is_black_image(synthetic_image):\n",
    "            continue\n",
    "        \n",
    "        output_filename = f\"{os.path.splitext(img_name)[0]}_aug_{num_needed}.png\"\n",
    "        synthetic_image.save(os.path.join(augmented_class_path, output_filename))\n",
    "        num_needed -= 1\n",
    "\n",
    "print(f\"Balanced dataset (Category-Specific Diffusion) saved at '{output_dir}'!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
