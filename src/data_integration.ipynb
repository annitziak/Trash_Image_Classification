{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Path to the dataset folder, not a single class folder\n",
    "dataset_path = r\"C:\\Users\\vidia\\OneDrive\\Documents\\mlp_proj\\mlp_assignment\\data\\dataset-resized\"\n",
    "dataset_path2 = r\"C:\\Users\\vidia\\OneDrive\\Documents\\mlp_proj\\mlp_assignment\\data\\realwaste-main\\RealWaste\"\n",
    "# Load dataset correctly\n",
    "trashNet_dataset = datasets.ImageFolder(root=dataset_path)\n",
    "realWaste_dataset = datasets.ImageFolder(root=dataset_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "\"cardboard\": \"cardboard\",  \n",
    "\"Cardboard\": \"cardboard\",  \n",
    "\"Glass\": \"glass\",\n",
    "\"glass\": \"glass\",\n",
    "\"Metal\": \"metal\",\n",
    "\"metal\": \"metal\",\n",
    "\"paper\": \"paper\",\n",
    "\"Paper\": \"paper\",\n",
    "\"plastic\": \"plastic\",\n",
    "\"Plastic\": \"plastic\",\n",
    "\"trash\": \"trash\",\n",
    "\"Food Organics\": \"trash\",\n",
    "\"Miscellaneous Trash\": \"trash\",\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    " \n",
    "# class MergedDataset(Dataset):\n",
    "#     def __init__(self, datasets, class_mapping):\n",
    "#         self.samples = []\n",
    "#         self.class_mapping = class_mapping\n",
    "#         self.new_classes = sorted(set(class_mapping.values()))  # Unique merged class names\n",
    "#         self.class_to_idx = {cls: i for i, cls in enumerate(self.new_classes)}  # New class indices\n",
    " \n",
    "#         # Process each dataset\n",
    "#         for dataset in datasets:\n",
    "#             for img_path, label in dataset.samples:\n",
    "#                 original_class = dataset.classes[label]\n",
    "#                 if original_class in class_mapping:\n",
    "#                     new_label = self.class_to_idx[class_mapping[original_class]]\n",
    "#                     self.samples.append((img_path, new_label))\n",
    " \n",
    "#         self.transform = datasets[0].transform  # Use the same transform\n",
    " \n",
    "#     def __len__(self):\n",
    "#         return len(self.samples)\n",
    " \n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path, label = self.samples[idx]\n",
    "#         image = datasets.folder.default_loader(img_path)  # Load image\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = MergedDataset([trashNet_dataset, realWaste_dataset], class_mapping)\n",
    " \n",
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(merged_dataset, batch_size=32, shuffle=True)\n",
    " \n",
    "# Print new class names\n",
    "print(\"Merged Classes:\", merged_dataset.new_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vidia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest width: 512, Smallest height: 384\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "data_root = 'dataset_augmented/'\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  str(data_root),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in dataset 1: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
      "Classes in dataset 2: ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n",
      "Dataset merging and relabeling completed!\n",
      "Found 6525 files belonging to 6 classes.\n",
      "Using 5220 files for training.\n",
      "Found 6525 files belonging to 6 classes.\n",
      "Using 1305 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "data_root1 = r\"C:\\Users\\vidia\\OneDrive\\Documents\\mlp_proj\\mlp_assignment\\data\\dataset-resized\"\n",
    "data_root2 = r\"C:\\Users\\vidia\\OneDrive\\Documents\\mlp_proj\\mlp_assignment\\data\\realwaste-main\\RealWaste\"\n",
    "# Extract class names from both datasets\n",
    "classes1 = sorted(os.listdir(data_root1))\n",
    "classes2 = sorted(os.listdir(data_root2))\n",
    "\n",
    "# Print detected class names\n",
    "print(\"Classes in dataset 1:\", classes1)\n",
    "print(\"Classes in dataset 2:\", classes2)\n",
    "\n",
    "# Manual mapping if class names differ\n",
    "class_mapping = {\n",
    "\"cardboard\": \"cardboard\",  \n",
    "\"Cardboard\": \"cardboard\",  \n",
    "\"Glass\": \"glass\",\n",
    "\"glass\": \"glass\",\n",
    "\"Metal\": \"metal\",\n",
    "\"metal\": \"metal\",\n",
    "\"paper\": \"paper\",\n",
    "\"Paper\": \"paper\",\n",
    "\"plastic\": \"plastic\",\n",
    "\"Plastic\": \"plastic\",\n",
    "\"trash\": \"trash\",\n",
    "\"Food Organics\": \"trash\",\n",
    "\"Miscellaneous Trash\": \"trash\",\n",
    "}\n",
    " \n",
    "# Create a unified directory structure\n",
    "unified_dataset_path = 'dataset_merged/'\n",
    "os.makedirs(unified_dataset_path, exist_ok=True)\n",
    "\n",
    "# Function to copy & relabel images into a unified dataset\n",
    "def copy_and_relabel_images(source_folder, target_folder, mapping):\n",
    "    for original_class in os.listdir(source_folder):\n",
    "        if original_class in mapping:  # Only process known classes\n",
    "            new_class = mapping[original_class]\n",
    "            source_class_path = os.path.join(source_folder, original_class)\n",
    "            target_class_path = os.path.join(target_folder, new_class)\n",
    "\n",
    "            os.makedirs(target_class_path, exist_ok=True)  # Create target class folder if not exist\n",
    "            \n",
    "            for img_name in os.listdir(source_class_path):\n",
    "                source_img_path = os.path.join(source_class_path, img_name)\n",
    "                target_img_path = os.path.join(target_class_path, img_name)\n",
    "                shutil.copy2(source_img_path, target_img_path)  # Copy image to correct folder\n",
    "\n",
    "# Copy images from both datasets into the unified dataset\n",
    "copy_and_relabel_images(data_root1, unified_dataset_path, class_mapping)\n",
    "copy_and_relabel_images(data_root2, unified_dataset_path, class_mapping)\n",
    "\n",
    "print(\"Dataset merging and relabeling completed!\")\n",
    "\n",
    "# Now, use `image_dataset_from_directory` on the new merged dataset\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    unified_dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    unified_dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class cardboard: 692 training, 172 validation\n",
      "Class glass: 737 training, 184 validation\n",
      "Class metal: 960 training, 240 validation\n",
      "Class paper: 876 training, 218 validation\n",
      "Class plastic: 1123 training, 280 validation\n",
      "Class trash: 835 training, 208 validation\n",
      "Train and validation split completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "merged_dataset_path = \"dataset_merged\"\n",
    "split_dataset_path = \"dataset_split\"\n",
    "train_path = os.path.join(split_dataset_path, \"train\")\n",
    "val_path = os.path.join(split_dataset_path, \"val\")\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "# Function to split dataset\n",
    "def split_dataset(source_path, train_dest, val_dest, val_ratio=0.2):\n",
    "    \"\"\"Splits images into training and validation folders.\"\"\"\n",
    "    for class_name in os.listdir(source_path):\n",
    "        class_source_path = os.path.join(source_path, class_name)\n",
    "        class_train_path = os.path.join(train_dest, class_name)\n",
    "        class_val_path = os.path.join(val_dest, class_name)\n",
    "\n",
    "        # Create class directories if they don't exist\n",
    "        os.makedirs(class_train_path, exist_ok=True)\n",
    "        os.makedirs(class_val_path, exist_ok=True)\n",
    "\n",
    "        # Get all images\n",
    "        images = os.listdir(class_source_path)\n",
    "        random.shuffle(images)  # Shuffle for randomness\n",
    "\n",
    "        # Compute split sizes\n",
    "        val_size = int(len(images) * val_ratio)\n",
    "        train_images = images[val_size:]\n",
    "        val_images = images[:val_size]\n",
    "\n",
    "        # Move images to respective folders\n",
    "        for img in train_images:\n",
    "            shutil.move(os.path.join(class_source_path, img), os.path.join(class_train_path, img))\n",
    "        \n",
    "        for img in val_images:\n",
    "            shutil.move(os.path.join(class_source_path, img), os.path.join(class_val_path, img))\n",
    "\n",
    "        print(f\"Class {class_name}: {len(train_images)} training, {len(val_images)} validation\")\n",
    "\n",
    "# Apply function\n",
    "split_dataset(merged_dataset_path, train_path, val_path)\n",
    "\n",
    "print(\"Train and validation split completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_dataset_path = 'dataset_merged/'\n",
    "merged_dataset = datasets.ImageFolder(root=unified_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard: 864\n",
      "glass: 921\n",
      "metal: 1200\n",
      "paper: 1094\n",
      "plastic: 1403\n",
      "trash: 1043\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    " \n",
    "# Count occurrences of each class\n",
    "class_counts = Counter(label for _, label in merged_dataset)\n",
    " \n",
    "# Print counts for each class\n",
    "for class_name, class_idx in merged_dataset.class_to_idx.items():\n",
    "    print(f\"{class_name}: {class_counts[class_idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_kernel",
   "language": "python",
   "name": "myproject_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
