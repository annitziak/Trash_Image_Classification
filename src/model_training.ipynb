{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../data/combined_dataset/'\n",
    "\n",
    "params = { 'batch_size':16,\n",
    "           'shuffle':True,\n",
    "           'num_workers':4 }\n",
    "\n",
    "# train dataset\n",
    "transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.RandomResizedCrop(256),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "train_dataset = datasets.ImageFolder(os.path.join(dir, 'train'),transform = transform )\n",
    "\n",
    "# validation dataset\n",
    "transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(256),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "dir = '../data/dataset_split'\n",
    "val_dataset = datasets.ImageFolder(os.path.join(dir, 'val'),transform = transform )\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, **params)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, **params)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset = 8832\n",
      " Val dataset = 719\n",
      "Classes = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset = {}\\n'.format(len(train_dataset)),'Val dataset = {}'.format(len(val_dataset)))\n",
    "print('Classes = {}'.format(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop for Model Fine-Tuning with Epoch-wise Performance Tracking and Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, num_epochs=25, save_path='trained_combined_augmentations_version_01_val_densenet.csv'):\n",
    "    best_acc = 0\n",
    "    results = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}'.format(epoch+1))\n",
    "        \n",
    "        # Train dataset\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        size = len(train_dataset)\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "            \n",
    "        train_loss = train_loss / size\n",
    "        train_acc = train_correct.double() / size\n",
    "            \n",
    "        print('Training Loss: {:.4f} Acc: {:.4f}'.format(train_loss, train_acc))\n",
    "        \n",
    "        # Validation dataset\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        size = len(val_dataset)\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_correct += torch.sum(preds == labels.data) \n",
    "\n",
    "        val_loss = val_loss / size\n",
    "        val_acc = val_correct.double() / size    \n",
    "\n",
    "        print('Validation Loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc))    \n",
    "            \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "\n",
    "        results.append([epoch + 1, [train_loss], [train_acc.item()], [val_loss], [val_acc.item()]])\n",
    "    \n",
    "    df = pd.DataFrame(results, columns=['Epoch', 'Train Loss', 'Train Accuracy', 'Validation Loss', 'Validation Accuracy'])\n",
    "    df.to_csv(save_path, index=False)\n",
    "    \n",
    "    print('Best Validation Accuracy: {:.4f}'.format(best_acc))\n",
    "    print(f'Training results saved to {save_path}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning DenseNet-121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.densenet121(pretrained=True)\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "ft = net.classifier.in_features\n",
    "net.classifier = nn.Linear(ft, 6)\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.classifier.parameters(), lr=0.0001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Loss: 1.6024 Acc: 0.3682\n",
      "Validation Loss: 1.2911 Acc: 0.5925\n",
      "Epoch 2\n",
      "Training Loss: 1.3369 Acc: 0.5302\n",
      "Validation Loss: 1.0846 Acc: 0.6676\n",
      "Epoch 3\n",
      "Training Loss: 1.2231 Acc: 0.5731\n",
      "Validation Loss: 0.9833 Acc: 0.6982\n",
      "Epoch 4\n",
      "Training Loss: 1.1587 Acc: 0.5931\n",
      "Validation Loss: 0.9110 Acc: 0.7093\n",
      "Epoch 5\n",
      "Training Loss: 1.1045 Acc: 0.6120\n",
      "Validation Loss: 0.8681 Acc: 0.7149\n",
      "Epoch 6\n",
      "Training Loss: 1.0655 Acc: 0.6192\n",
      "Validation Loss: 0.8421 Acc: 0.7330\n",
      "Epoch 7\n",
      "Training Loss: 1.0434 Acc: 0.6298\n",
      "Validation Loss: 0.8196 Acc: 0.7232\n",
      "Epoch 8\n",
      "Training Loss: 1.0272 Acc: 0.6291\n",
      "Validation Loss: 0.8079 Acc: 0.7302\n",
      "Epoch 9\n",
      "Training Loss: 1.0089 Acc: 0.6377\n",
      "Validation Loss: 0.7854 Acc: 0.7371\n",
      "Epoch 10\n",
      "Training Loss: 0.9963 Acc: 0.6409\n",
      "Validation Loss: 0.7624 Acc: 0.7497\n",
      "Epoch 11\n",
      "Training Loss: 0.9883 Acc: 0.6447\n",
      "Validation Loss: 0.7448 Acc: 0.7552\n",
      "Epoch 12\n",
      "Training Loss: 0.9648 Acc: 0.6574\n",
      "Validation Loss: 0.7468 Acc: 0.7469\n",
      "Epoch 13\n",
      "Training Loss: 0.9617 Acc: 0.6504\n",
      "Validation Loss: 0.7236 Acc: 0.7552\n",
      "Epoch 14\n",
      "Training Loss: 0.9452 Acc: 0.6618\n",
      "Validation Loss: 0.7163 Acc: 0.7510\n",
      "Epoch 15\n",
      "Training Loss: 0.9496 Acc: 0.6553\n",
      "Validation Loss: 0.7289 Acc: 0.7441\n",
      "Epoch 16\n",
      "Training Loss: 0.9283 Acc: 0.6651\n",
      "Validation Loss: 0.7164 Acc: 0.7510\n",
      "Epoch 17\n",
      "Training Loss: 0.9246 Acc: 0.6617\n",
      "Validation Loss: 0.7115 Acc: 0.7441\n",
      "Epoch 18\n",
      "Training Loss: 0.9279 Acc: 0.6694\n",
      "Validation Loss: 0.7041 Acc: 0.7455\n",
      "Epoch 19\n",
      "Training Loss: 0.9180 Acc: 0.6646\n",
      "Validation Loss: 0.6961 Acc: 0.7538\n",
      "Epoch 20\n",
      "Training Loss: 0.9149 Acc: 0.6688\n",
      "Validation Loss: 0.6944 Acc: 0.7580\n",
      "Epoch 21\n",
      "Training Loss: 0.9080 Acc: 0.6709\n",
      "Validation Loss: 0.6845 Acc: 0.7636\n",
      "Epoch 22\n",
      "Training Loss: 0.9085 Acc: 0.6720\n",
      "Validation Loss: 0.6807 Acc: 0.7677\n",
      "Epoch 23\n",
      "Training Loss: 0.8985 Acc: 0.6719\n",
      "Validation Loss: 0.6810 Acc: 0.7705\n",
      "Epoch 24\n",
      "Training Loss: 0.8992 Acc: 0.6753\n",
      "Validation Loss: 0.6797 Acc: 0.7622\n",
      "Epoch 25\n",
      "Training Loss: 0.9009 Acc: 0.6762\n",
      "Validation Loss: 0.6911 Acc: 0.7636\n",
      "Epoch 26\n",
      "Training Loss: 0.8933 Acc: 0.6780\n",
      "Validation Loss: 0.6834 Acc: 0.7663\n",
      "Epoch 27\n",
      "Training Loss: 0.8996 Acc: 0.6704\n",
      "Validation Loss: 0.6685 Acc: 0.7761\n",
      "Epoch 28\n",
      "Training Loss: 0.8727 Acc: 0.6831\n",
      "Validation Loss: 0.6642 Acc: 0.7636\n",
      "Epoch 29\n",
      "Training Loss: 0.8719 Acc: 0.6798\n",
      "Validation Loss: 0.6680 Acc: 0.7663\n",
      "Epoch 30\n",
      "Training Loss: 0.8761 Acc: 0.6779\n",
      "Validation Loss: 0.6717 Acc: 0.7622\n",
      "Epoch 31\n",
      "Training Loss: 0.8754 Acc: 0.6881\n",
      "Validation Loss: 0.6653 Acc: 0.7719\n",
      "Epoch 32\n",
      "Training Loss: 0.8746 Acc: 0.6826\n",
      "Validation Loss: 0.6611 Acc: 0.7663\n",
      "Epoch 33\n",
      "Training Loss: 0.8629 Acc: 0.6894\n",
      "Validation Loss: 0.6456 Acc: 0.7733\n",
      "Epoch 34\n",
      "Training Loss: 0.8715 Acc: 0.6872\n",
      "Validation Loss: 0.6513 Acc: 0.7775\n",
      "Epoch 35\n",
      "Training Loss: 0.8650 Acc: 0.6804\n",
      "Validation Loss: 0.6528 Acc: 0.7636\n",
      "Epoch 36\n",
      "Training Loss: 0.8786 Acc: 0.6772\n",
      "Validation Loss: 0.6432 Acc: 0.7747\n",
      "Epoch 37\n",
      "Training Loss: 0.8501 Acc: 0.6945\n",
      "Validation Loss: 0.6570 Acc: 0.7747\n",
      "Epoch 38\n",
      "Training Loss: 0.8573 Acc: 0.6893\n",
      "Validation Loss: 0.6512 Acc: 0.7705\n",
      "Epoch 39\n",
      "Training Loss: 0.8679 Acc: 0.6839\n",
      "Validation Loss: 0.6463 Acc: 0.7747\n",
      "Epoch 40\n",
      "Training Loss: 0.8673 Acc: 0.6809\n",
      "Validation Loss: 0.6380 Acc: 0.7789\n",
      "Epoch 41\n",
      "Training Loss: 0.8603 Acc: 0.6894\n",
      "Validation Loss: 0.6585 Acc: 0.7705\n",
      "Epoch 42\n",
      "Training Loss: 0.8499 Acc: 0.6923\n",
      "Validation Loss: 0.6542 Acc: 0.7747\n",
      "Epoch 43\n",
      "Training Loss: 0.8582 Acc: 0.6929\n",
      "Validation Loss: 0.6557 Acc: 0.7636\n",
      "Epoch 44\n",
      "Training Loss: 0.8520 Acc: 0.6901\n",
      "Validation Loss: 0.6390 Acc: 0.7733\n",
      "Epoch 45\n",
      "Training Loss: 0.8527 Acc: 0.6925\n",
      "Validation Loss: 0.6401 Acc: 0.7761\n",
      "Epoch 46\n",
      "Training Loss: 0.8624 Acc: 0.6791\n",
      "Validation Loss: 0.6474 Acc: 0.7747\n",
      "Epoch 47\n",
      "Training Loss: 0.8436 Acc: 0.6906\n",
      "Validation Loss: 0.6481 Acc: 0.7733\n",
      "Epoch 48\n",
      "Training Loss: 0.8460 Acc: 0.6953\n",
      "Validation Loss: 0.6435 Acc: 0.7789\n",
      "Epoch 49\n",
      "Training Loss: 0.8586 Acc: 0.6830\n",
      "Validation Loss: 0.6320 Acc: 0.7775\n",
      "Epoch 50\n",
      "Training Loss: 0.8452 Acc: 0.6953\n",
      "Validation Loss: 0.6376 Acc: 0.7803\n",
      "Epoch 51\n",
      "Training Loss: 0.8435 Acc: 0.6964\n",
      "Validation Loss: 0.6471 Acc: 0.7789\n",
      "Epoch 52\n",
      "Training Loss: 0.8427 Acc: 0.6950\n",
      "Validation Loss: 0.6262 Acc: 0.7803\n",
      "Epoch 53\n",
      "Training Loss: 0.8394 Acc: 0.6937\n",
      "Validation Loss: 0.6316 Acc: 0.7789\n",
      "Epoch 54\n",
      "Training Loss: 0.8459 Acc: 0.6865\n",
      "Validation Loss: 0.6407 Acc: 0.7650\n",
      "Epoch 55\n",
      "Training Loss: 0.8437 Acc: 0.6960\n",
      "Validation Loss: 0.6351 Acc: 0.7747\n",
      "Epoch 56\n",
      "Training Loss: 0.8429 Acc: 0.6946\n",
      "Validation Loss: 0.6333 Acc: 0.7816\n",
      "Epoch 57\n",
      "Training Loss: 0.8297 Acc: 0.6998\n",
      "Validation Loss: 0.6245 Acc: 0.7830\n",
      "Epoch 58\n",
      "Training Loss: 0.8385 Acc: 0.6974\n",
      "Validation Loss: 0.6295 Acc: 0.7830\n",
      "Epoch 59\n",
      "Training Loss: 0.8374 Acc: 0.6947\n",
      "Validation Loss: 0.6256 Acc: 0.7761\n",
      "Epoch 60\n",
      "Training Loss: 0.8468 Acc: 0.6942\n",
      "Validation Loss: 0.6336 Acc: 0.7747\n",
      "Epoch 61\n",
      "Training Loss: 0.8323 Acc: 0.6990\n",
      "Validation Loss: 0.6268 Acc: 0.7803\n",
      "Epoch 62\n",
      "Training Loss: 0.8290 Acc: 0.6977\n",
      "Validation Loss: 0.6212 Acc: 0.7747\n",
      "Epoch 63\n",
      "Training Loss: 0.8278 Acc: 0.7017\n",
      "Validation Loss: 0.6299 Acc: 0.7733\n",
      "Epoch 64\n",
      "Training Loss: 0.8327 Acc: 0.6987\n",
      "Validation Loss: 0.6216 Acc: 0.7789\n",
      "Epoch 65\n",
      "Training Loss: 0.8204 Acc: 0.7015\n",
      "Validation Loss: 0.6304 Acc: 0.7622\n",
      "Epoch 66\n",
      "Training Loss: 0.8298 Acc: 0.6942\n",
      "Validation Loss: 0.6298 Acc: 0.7830\n",
      "Epoch 67\n",
      "Training Loss: 0.8321 Acc: 0.6953\n",
      "Validation Loss: 0.6296 Acc: 0.7872\n",
      "Epoch 68\n",
      "Training Loss: 0.8313 Acc: 0.6970\n",
      "Validation Loss: 0.6207 Acc: 0.7816\n",
      "Epoch 69\n",
      "Training Loss: 0.8208 Acc: 0.7011\n",
      "Validation Loss: 0.6172 Acc: 0.7858\n",
      "Epoch 70\n",
      "Training Loss: 0.8229 Acc: 0.6974\n",
      "Validation Loss: 0.6169 Acc: 0.7789\n",
      "Epoch 71\n",
      "Training Loss: 0.8236 Acc: 0.6975\n",
      "Validation Loss: 0.6116 Acc: 0.7844\n",
      "Epoch 72\n",
      "Training Loss: 0.8121 Acc: 0.7061\n",
      "Validation Loss: 0.6291 Acc: 0.7775\n",
      "Epoch 73\n",
      "Training Loss: 0.8236 Acc: 0.7003\n",
      "Validation Loss: 0.6335 Acc: 0.7691\n",
      "Epoch 74\n",
      "Training Loss: 0.8232 Acc: 0.7045\n",
      "Validation Loss: 0.6146 Acc: 0.7816\n",
      "Epoch 75\n",
      "Training Loss: 0.8290 Acc: 0.6930\n",
      "Validation Loss: 0.6198 Acc: 0.7803\n",
      "Epoch 76\n",
      "Training Loss: 0.8173 Acc: 0.6987\n",
      "Validation Loss: 0.6005 Acc: 0.7844\n",
      "Epoch 77\n",
      "Training Loss: 0.8253 Acc: 0.7023\n",
      "Validation Loss: 0.6040 Acc: 0.7900\n",
      "Epoch 78\n",
      "Training Loss: 0.8300 Acc: 0.6962\n",
      "Validation Loss: 0.6122 Acc: 0.7803\n",
      "Epoch 79\n",
      "Training Loss: 0.8117 Acc: 0.7009\n",
      "Validation Loss: 0.6271 Acc: 0.7747\n",
      "Epoch 80\n",
      "Training Loss: 0.8178 Acc: 0.7097\n",
      "Validation Loss: 0.6159 Acc: 0.7761\n",
      "Epoch 81\n",
      "Training Loss: 0.8252 Acc: 0.6975\n",
      "Validation Loss: 0.6220 Acc: 0.7830\n",
      "Epoch 82\n",
      "Training Loss: 0.8332 Acc: 0.6927\n",
      "Validation Loss: 0.6239 Acc: 0.7816\n",
      "Epoch 83\n",
      "Training Loss: 0.8146 Acc: 0.7039\n",
      "Validation Loss: 0.6083 Acc: 0.7830\n",
      "Epoch 84\n",
      "Training Loss: 0.8168 Acc: 0.7049\n",
      "Validation Loss: 0.6111 Acc: 0.7775\n",
      "Epoch 85\n",
      "Training Loss: 0.8304 Acc: 0.7013\n",
      "Validation Loss: 0.6185 Acc: 0.7928\n",
      "Epoch 86\n",
      "Training Loss: 0.8196 Acc: 0.7021\n",
      "Validation Loss: 0.6158 Acc: 0.7886\n",
      "Epoch 87\n",
      "Training Loss: 0.8061 Acc: 0.7000\n",
      "Validation Loss: 0.6047 Acc: 0.7886\n",
      "Epoch 88\n",
      "Training Loss: 0.8186 Acc: 0.7045\n",
      "Validation Loss: 0.6032 Acc: 0.7816\n",
      "Epoch 89\n",
      "Training Loss: 0.8238 Acc: 0.7009\n",
      "Validation Loss: 0.6100 Acc: 0.7830\n",
      "Epoch 90\n",
      "Training Loss: 0.8050 Acc: 0.7064\n",
      "Validation Loss: 0.6186 Acc: 0.7761\n",
      "Epoch 91\n",
      "Training Loss: 0.8010 Acc: 0.7079\n",
      "Validation Loss: 0.6167 Acc: 0.7789\n",
      "Epoch 92\n",
      "Training Loss: 0.8078 Acc: 0.7021\n",
      "Validation Loss: 0.6108 Acc: 0.7830\n",
      "Epoch 93\n",
      "Training Loss: 0.8142 Acc: 0.7011\n",
      "Validation Loss: 0.6165 Acc: 0.7747\n",
      "Epoch 94\n",
      "Training Loss: 0.8142 Acc: 0.7018\n",
      "Validation Loss: 0.6138 Acc: 0.7900\n",
      "Epoch 95\n",
      "Training Loss: 0.8070 Acc: 0.7041\n",
      "Validation Loss: 0.6167 Acc: 0.7803\n",
      "Epoch 96\n",
      "Training Loss: 0.8085 Acc: 0.7069\n",
      "Validation Loss: 0.6176 Acc: 0.7886\n",
      "Epoch 97\n",
      "Training Loss: 0.8169 Acc: 0.7019\n",
      "Validation Loss: 0.6070 Acc: 0.7691\n",
      "Epoch 98\n",
      "Training Loss: 0.8039 Acc: 0.7124\n",
      "Validation Loss: 0.5989 Acc: 0.7858\n",
      "Epoch 99\n",
      "Training Loss: 0.8094 Acc: 0.7049\n",
      "Validation Loss: 0.6189 Acc: 0.7775\n",
      "Epoch 100\n",
      "Training Loss: 0.8114 Acc: 0.7034\n",
      "Validation Loss: 0.6272 Acc: 0.7691\n",
      "Best Validation Accuracy: 0.7928\n",
      "Training results saved to trained_combined_augmentations_version_01_val_densenet.csv\n"
     ]
    }
   ],
   "source": [
    "net = train(net,loss,optimizer,num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the parameters of the desnet model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as trained_densenet.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(net.state_dict(), \"trained_combined_modell_val_densenet.pth\")  # Save model weights\n",
    "print(\"Model saved as trained_densenet.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
