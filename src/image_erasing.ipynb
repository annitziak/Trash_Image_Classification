{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augemntation - Image Erasing\n",
    "1. Hide and Seek -> divides the image into random regions and removes some, masking multiple parts at the same time\n",
    "2. CoarseDropout -> removes a fixed-size subregion\n",
    "3. GridDropout -> overlaying a transparent grid, blacking out the rest of the image\n",
    "4. RandomErasing -> replaces a randomly selected rectangular region with a black box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import albumentations as A #this supposedly is much faster than using torchvision\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation Pipeline (Balanced Erasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide_and_seek(image, **kwargs):  \n",
    "    \"\"\"\n",
    "    Less aggressive Hide-and-Seek occlusion technique without altering colors.\n",
    "    \"\"\"\n",
    "    if isinstance(image, np.ndarray):\n",
    "        img = np.transpose(image, (2, 0, 1))\n",
    "        img = img.copy()  \n",
    "    else:\n",
    "        img = image.clone() if isinstance(image, torch.Tensor) else image  \n",
    " \n",
    "    c, h, w = img.shape  \n",
    "    grid_sizes = [12, 24, 36, 48]\n",
    "    hide_prob = 0.2  # Reduced probability to erase smaller portions\n",
    " \n",
    "    grid_size = random.choice(grid_sizes)\n",
    " \n",
    "    for x in range(0, w, grid_size):\n",
    "        for y in range(0, h, grid_size):\n",
    "            x_end = min(w, x + grid_size)\n",
    "            y_end = min(h, y + grid_size)\n",
    "            if random.random() <= hide_prob:\n",
    "                img[:, y:y_end, x:x_end] = 0\n",
    " \n",
    "    if isinstance(image, np.ndarray):\n",
    "        img = np.transpose(img, (1, 2, 0))  \n",
    " \n",
    "    return img\n",
    "\n",
    "def get_random_augmentation():\n",
    "    \"\"\"\n",
    "    Randomly selects and returns one augmentation technique without altering colors.\n",
    "    \"\"\"\n",
    "    augmentations = [\n",
    "        A.CoarseDropout(max_holes=10, max_height=50, max_width=50, fill_value=0, p=1.0),\n",
    "        A.GridDropout(ratio=0.45, p=1.0),\n",
    "        A.Lambda(image=hide_and_seek, p=1.0),\n",
    "        A.Erasing(p=1.0, scale=(0.05, 0.5), ratio=(0.25, 4.0), value=0) \n",
    "    ]\n",
    "    return A.Compose([random.choice(augmentations), ToTensorV2()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the pipeline to balance the dataset\n",
    "### Idea : The augmented images at each catergory must all be equal to majority_class*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "input_dir = \"../data/dataset_split/train\"  \n",
    "output_dir = \"../data/dataset_erasing/train\"\n",
    " \n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "    \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    " \n",
    "class_counts = {}\n",
    "for class_folder in os.listdir(input_dir):\n",
    "    class_path = os.path.join(input_dir, class_folder)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    class_counts[class_folder] = num_images\n",
    " \n",
    "change_factor = 2  # Increase the number of images in each class by 2x\n",
    "max_class_size = max(class_counts.values())\n",
    "new_target_size = max_class_size * change_factor\n",
    " \n",
    "print(class_counts)\n",
    "print(f\"Max category is {max_class_size} of class {max(class_counts, key=class_counts.get)}\")\n",
    " \n",
    "for class_folder, current_count in tqdm(class_counts.items(), desc=\"Balancing & Expanding Classes\"):\n",
    "    class_path = os.path.join(input_dir, class_folder)\n",
    "    augmented_class_path = os.path.join(output_dir, class_folder)\n",
    "    os.makedirs(augmented_class_path, exist_ok=True)\n",
    " \n",
    "    images = os.listdir(class_path)\n",
    "    \n",
    "    for img_name in images:\n",
    "        src_path = os.path.join(class_path, img_name)\n",
    "        dst_path = os.path.join(augmented_class_path, img_name)\n",
    "        img = cv2.imread(src_path)\n",
    "        cv2.imwrite(dst_path, img)\n",
    " \n",
    "    # Compute number of extra images needed\n",
    "    num_needed = new_target_size - current_count\n",
    " \n",
    "    while num_needed > 0:\n",
    "        for img_name in images:\n",
    "            if num_needed <= 0:\n",
    "                break\n",
    " \n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            image = cv2.imread(img_path)\n",
    " \n",
    "            augmentation_pipeline = get_random_augmentation()\n",
    "            augmented = augmentation_pipeline(image=image)[\"image\"]\n",
    " \n",
    "            if isinstance(augmented, torch.Tensor):  \n",
    "                augmented = augmented.clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()\n",
    " \n",
    "            output_filename = f\"{os.path.splitext(img_name)[0]}_aug_{num_needed}.png\"\n",
    "            output_path = os.path.join(augmented_class_path, output_filename)\n",
    "            cv2.imwrite(output_path, augmented)\n",
    "            num_needed -= 1\n",
    " \n",
    "print(f\"Dataset balanced & expanded! New images saved in {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
